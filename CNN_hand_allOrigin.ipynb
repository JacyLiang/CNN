{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f422bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe\n",
      "  Downloading mediapipe-0.9.0.1-cp38-cp38-win_amd64.whl (49.8 MB)\n",
      "     --------------------------------------- 49.8/49.8 MB 13.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in c:\\users\\tibame_t14\\anaconda3\\envs\\tensorflow2_gpu\\lib\\site-packages (from mediapipe) (3.19.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\tibame_t14\\anaconda3\\envs\\tensorflow2_gpu\\lib\\site-packages (from mediapipe) (1.23.5)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-22.12.6-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\tibame_t14\\anaconda3\\envs\\tensorflow2_gpu\\lib\\site-packages (from mediapipe) (22.1.0)\n",
      "Collecting opencv-contrib-python\n",
      "  Using cached opencv_contrib_python-4.6.0.66-cp36-abi3-win_amd64.whl (42.5 MB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\tibame_t14\\anaconda3\\envs\\tensorflow2_gpu\\lib\\site-packages (from mediapipe) (3.6.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\tibame_t14\\anaconda3\\envs\\tensorflow2_gpu\\lib\\site-packages (from mediapipe) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\tibame_t14\\anaconda3\\envs\\tensorflow2_gpu\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\tibame_t14\\anaconda3\\envs\\tensorflow2_gpu\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\tibame_t14\\anaconda3\\envs\\tensorflow2_gpu\\lib\\site-packages (from matplotlib->mediapipe) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\tibame_t14\\anaconda3\\envs\\tensorflow2_gpu\\lib\\site-packages (from matplotlib->mediapipe) (3.0.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\tibame_t14\\anaconda3\\envs\\tensorflow2_gpu\\lib\\site-packages (from matplotlib->mediapipe) (9.3.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\tibame_t14\\anaconda3\\envs\\tensorflow2_gpu\\lib\\site-packages (from matplotlib->mediapipe) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\tibame_t14\\anaconda3\\envs\\tensorflow2_gpu\\lib\\site-packages (from matplotlib->mediapipe) (1.0.6)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\tibame_t14\\anaconda3\\envs\\tensorflow2_gpu\\lib\\site-packages (from matplotlib->mediapipe) (4.38.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tibame_t14\\anaconda3\\envs\\tensorflow2_gpu\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Installing collected packages: flatbuffers, opencv-contrib-python, mediapipe\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 1.12\n",
      "    Uninstalling flatbuffers-1.12:\n",
      "      Successfully uninstalled flatbuffers-1.12\n",
      "Successfully installed flatbuffers-22.12.6 mediapipe-0.9.0.1 opencv-contrib-python-4.6.0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.9.0 requires flatbuffers<2,>=1.12, but you have flatbuffers 22.12.6 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "#Add Python module called Mediapipe\n",
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cec82770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the much needed stuff for training\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import csv\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "# Checking Tensorflow Version\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e349657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_type</th>\n",
       "      <th>thumb_CmcX</th>\n",
       "      <th>thumb_CmcY</th>\n",
       "      <th>thumb_CmcZ</th>\n",
       "      <th>thumb_McpX</th>\n",
       "      <th>thumb_McpY</th>\n",
       "      <th>thumb_McpZ</th>\n",
       "      <th>thumb_IpX</th>\n",
       "      <th>thumb_IpY</th>\n",
       "      <th>thumb_IpZ</th>\n",
       "      <th>...</th>\n",
       "      <th>pinky_McpZ</th>\n",
       "      <th>pinky_PipX</th>\n",
       "      <th>pinky_PipY</th>\n",
       "      <th>pinky_PipZ</th>\n",
       "      <th>pinky_DipX</th>\n",
       "      <th>pinky_DipY</th>\n",
       "      <th>pinky_DipZ</th>\n",
       "      <th>pinky_TipX</th>\n",
       "      <th>pinky_TipY</th>\n",
       "      <th>pinky_TipZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.012261</td>\n",
       "      <td>-0.054713</td>\n",
       "      <td>-0.064790</td>\n",
       "      <td>0.046395</td>\n",
       "      <td>-0.081590</td>\n",
       "      <td>-0.106398</td>\n",
       "      <td>0.074692</td>\n",
       "      <td>-0.068785</td>\n",
       "      <td>-0.142921</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064073</td>\n",
       "      <td>0.047597</td>\n",
       "      <td>0.140222</td>\n",
       "      <td>-0.112481</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>0.150317</td>\n",
       "      <td>-0.113498</td>\n",
       "      <td>-0.044463</td>\n",
       "      <td>0.142457</td>\n",
       "      <td>-0.103716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23549</th>\n",
       "      <td>0</td>\n",
       "      <td>0.025092</td>\n",
       "      <td>-0.064440</td>\n",
       "      <td>-0.139927</td>\n",
       "      <td>0.098135</td>\n",
       "      <td>-0.107076</td>\n",
       "      <td>-0.221401</td>\n",
       "      <td>0.196540</td>\n",
       "      <td>-0.083356</td>\n",
       "      <td>-0.286363</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070091</td>\n",
       "      <td>0.295098</td>\n",
       "      <td>0.167263</td>\n",
       "      <td>-0.158358</td>\n",
       "      <td>0.201370</td>\n",
       "      <td>0.160428</td>\n",
       "      <td>-0.153877</td>\n",
       "      <td>0.148551</td>\n",
       "      <td>0.124910</td>\n",
       "      <td>-0.125677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23550</th>\n",
       "      <td>0</td>\n",
       "      <td>0.022196</td>\n",
       "      <td>-0.065882</td>\n",
       "      <td>-0.132180</td>\n",
       "      <td>0.102703</td>\n",
       "      <td>-0.110805</td>\n",
       "      <td>-0.203751</td>\n",
       "      <td>0.205004</td>\n",
       "      <td>-0.087554</td>\n",
       "      <td>-0.259828</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049213</td>\n",
       "      <td>0.308012</td>\n",
       "      <td>0.154426</td>\n",
       "      <td>-0.132990</td>\n",
       "      <td>0.220689</td>\n",
       "      <td>0.154105</td>\n",
       "      <td>-0.128571</td>\n",
       "      <td>0.168385</td>\n",
       "      <td>0.121921</td>\n",
       "      <td>-0.100112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23551</th>\n",
       "      <td>0</td>\n",
       "      <td>0.029679</td>\n",
       "      <td>-0.073904</td>\n",
       "      <td>-0.117726</td>\n",
       "      <td>0.113281</td>\n",
       "      <td>-0.122347</td>\n",
       "      <td>-0.179320</td>\n",
       "      <td>0.214193</td>\n",
       "      <td>-0.096491</td>\n",
       "      <td>-0.227835</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043005</td>\n",
       "      <td>0.313024</td>\n",
       "      <td>0.145701</td>\n",
       "      <td>-0.125747</td>\n",
       "      <td>0.223044</td>\n",
       "      <td>0.143749</td>\n",
       "      <td>-0.123801</td>\n",
       "      <td>0.169800</td>\n",
       "      <td>0.109868</td>\n",
       "      <td>-0.096811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23552</th>\n",
       "      <td>0</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>-0.080681</td>\n",
       "      <td>-0.098662</td>\n",
       "      <td>0.125531</td>\n",
       "      <td>-0.126880</td>\n",
       "      <td>-0.148170</td>\n",
       "      <td>0.230018</td>\n",
       "      <td>-0.100868</td>\n",
       "      <td>-0.189195</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032644</td>\n",
       "      <td>0.318775</td>\n",
       "      <td>0.128685</td>\n",
       "      <td>-0.110378</td>\n",
       "      <td>0.231798</td>\n",
       "      <td>0.126545</td>\n",
       "      <td>-0.107725</td>\n",
       "      <td>0.173329</td>\n",
       "      <td>0.097503</td>\n",
       "      <td>-0.080556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37095</th>\n",
       "      <td>4</td>\n",
       "      <td>0.039656</td>\n",
       "      <td>-0.033751</td>\n",
       "      <td>-0.127444</td>\n",
       "      <td>0.107512</td>\n",
       "      <td>-0.046348</td>\n",
       "      <td>-0.189851</td>\n",
       "      <td>0.195785</td>\n",
       "      <td>-0.005595</td>\n",
       "      <td>-0.231522</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025782</td>\n",
       "      <td>0.275776</td>\n",
       "      <td>0.102451</td>\n",
       "      <td>-0.089464</td>\n",
       "      <td>0.218746</td>\n",
       "      <td>0.112286</td>\n",
       "      <td>-0.098906</td>\n",
       "      <td>0.174507</td>\n",
       "      <td>0.092683</td>\n",
       "      <td>-0.089300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37094</th>\n",
       "      <td>4</td>\n",
       "      <td>0.045146</td>\n",
       "      <td>-0.038217</td>\n",
       "      <td>-0.120844</td>\n",
       "      <td>0.112096</td>\n",
       "      <td>-0.053228</td>\n",
       "      <td>-0.181130</td>\n",
       "      <td>0.200864</td>\n",
       "      <td>-0.010681</td>\n",
       "      <td>-0.223143</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033020</td>\n",
       "      <td>0.258502</td>\n",
       "      <td>0.115805</td>\n",
       "      <td>-0.097260</td>\n",
       "      <td>0.202204</td>\n",
       "      <td>0.115296</td>\n",
       "      <td>-0.104968</td>\n",
       "      <td>0.157365</td>\n",
       "      <td>0.088228</td>\n",
       "      <td>-0.092823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37093</th>\n",
       "      <td>4</td>\n",
       "      <td>0.045179</td>\n",
       "      <td>-0.046358</td>\n",
       "      <td>-0.112949</td>\n",
       "      <td>0.113749</td>\n",
       "      <td>-0.068758</td>\n",
       "      <td>-0.171630</td>\n",
       "      <td>0.201301</td>\n",
       "      <td>-0.025802</td>\n",
       "      <td>-0.214236</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042111</td>\n",
       "      <td>0.252671</td>\n",
       "      <td>0.116860</td>\n",
       "      <td>-0.104021</td>\n",
       "      <td>0.192834</td>\n",
       "      <td>0.110457</td>\n",
       "      <td>-0.107463</td>\n",
       "      <td>0.153796</td>\n",
       "      <td>0.079014</td>\n",
       "      <td>-0.091955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37065</th>\n",
       "      <td>4</td>\n",
       "      <td>0.048017</td>\n",
       "      <td>-0.042993</td>\n",
       "      <td>-0.113411</td>\n",
       "      <td>0.125094</td>\n",
       "      <td>-0.058465</td>\n",
       "      <td>-0.168289</td>\n",
       "      <td>0.216048</td>\n",
       "      <td>-0.007725</td>\n",
       "      <td>-0.206201</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031464</td>\n",
       "      <td>0.253758</td>\n",
       "      <td>0.127802</td>\n",
       "      <td>-0.094675</td>\n",
       "      <td>0.186126</td>\n",
       "      <td>0.119191</td>\n",
       "      <td>-0.094628</td>\n",
       "      <td>0.151503</td>\n",
       "      <td>0.080770</td>\n",
       "      <td>-0.076026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67803</th>\n",
       "      <td>4</td>\n",
       "      <td>0.029301</td>\n",
       "      <td>-0.069099</td>\n",
       "      <td>-0.064884</td>\n",
       "      <td>0.096214</td>\n",
       "      <td>-0.119432</td>\n",
       "      <td>-0.101427</td>\n",
       "      <td>0.168878</td>\n",
       "      <td>-0.128819</td>\n",
       "      <td>-0.132071</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052191</td>\n",
       "      <td>0.270327</td>\n",
       "      <td>0.060239</td>\n",
       "      <td>-0.105540</td>\n",
       "      <td>0.223794</td>\n",
       "      <td>0.077103</td>\n",
       "      <td>-0.116620</td>\n",
       "      <td>0.171071</td>\n",
       "      <td>0.079793</td>\n",
       "      <td>-0.111782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67804 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       class_type  thumb_CmcX  thumb_CmcY  thumb_CmcZ  thumb_McpX  thumb_McpY  \\\n",
       "0               0    0.012261   -0.054713   -0.064790    0.046395   -0.081590   \n",
       "23549           0    0.025092   -0.064440   -0.139927    0.098135   -0.107076   \n",
       "23550           0    0.022196   -0.065882   -0.132180    0.102703   -0.110805   \n",
       "23551           0    0.029679   -0.073904   -0.117726    0.113281   -0.122347   \n",
       "23552           0    0.035407   -0.080681   -0.098662    0.125531   -0.126880   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "37095           4    0.039656   -0.033751   -0.127444    0.107512   -0.046348   \n",
       "37094           4    0.045146   -0.038217   -0.120844    0.112096   -0.053228   \n",
       "37093           4    0.045179   -0.046358   -0.112949    0.113749   -0.068758   \n",
       "37065           4    0.048017   -0.042993   -0.113411    0.125094   -0.058465   \n",
       "67803           4    0.029301   -0.069099   -0.064884    0.096214   -0.119432   \n",
       "\n",
       "       thumb_McpZ  thumb_IpX  thumb_IpY  thumb_IpZ  ...  pinky_McpZ  \\\n",
       "0       -0.106398   0.074692  -0.068785  -0.142921  ...   -0.064073   \n",
       "23549   -0.221401   0.196540  -0.083356  -0.286363  ...   -0.070091   \n",
       "23550   -0.203751   0.205004  -0.087554  -0.259828  ...   -0.049213   \n",
       "23551   -0.179320   0.214193  -0.096491  -0.227835  ...   -0.043005   \n",
       "23552   -0.148170   0.230018  -0.100868  -0.189195  ...   -0.032644   \n",
       "...           ...        ...        ...        ...  ...         ...   \n",
       "37095   -0.189851   0.195785  -0.005595  -0.231522  ...   -0.025782   \n",
       "37094   -0.181130   0.200864  -0.010681  -0.223143  ...   -0.033020   \n",
       "37093   -0.171630   0.201301  -0.025802  -0.214236  ...   -0.042111   \n",
       "37065   -0.168289   0.216048  -0.007725  -0.206201  ...   -0.031464   \n",
       "67803   -0.101427   0.168878  -0.128819  -0.132071  ...   -0.052191   \n",
       "\n",
       "       pinky_PipX  pinky_PipY  pinky_PipZ  pinky_DipX  pinky_DipY  pinky_DipZ  \\\n",
       "0        0.047597    0.140222   -0.112481    0.002290    0.150317   -0.113498   \n",
       "23549    0.295098    0.167263   -0.158358    0.201370    0.160428   -0.153877   \n",
       "23550    0.308012    0.154426   -0.132990    0.220689    0.154105   -0.128571   \n",
       "23551    0.313024    0.145701   -0.125747    0.223044    0.143749   -0.123801   \n",
       "23552    0.318775    0.128685   -0.110378    0.231798    0.126545   -0.107725   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "37095    0.275776    0.102451   -0.089464    0.218746    0.112286   -0.098906   \n",
       "37094    0.258502    0.115805   -0.097260    0.202204    0.115296   -0.104968   \n",
       "37093    0.252671    0.116860   -0.104021    0.192834    0.110457   -0.107463   \n",
       "37065    0.253758    0.127802   -0.094675    0.186126    0.119191   -0.094628   \n",
       "67803    0.270327    0.060239   -0.105540    0.223794    0.077103   -0.116620   \n",
       "\n",
       "       pinky_TipX  pinky_TipY  pinky_TipZ  \n",
       "0       -0.044463    0.142457   -0.103716  \n",
       "23549    0.148551    0.124910   -0.125677  \n",
       "23550    0.168385    0.121921   -0.100112  \n",
       "23551    0.169800    0.109868   -0.096811  \n",
       "23552    0.173329    0.097503   -0.080556  \n",
       "...           ...         ...         ...  \n",
       "37095    0.174507    0.092683   -0.089300  \n",
       "37094    0.157365    0.088228   -0.092823  \n",
       "37093    0.153796    0.079014   -0.091955  \n",
       "37065    0.151503    0.080770   -0.076026  \n",
       "67803    0.171071    0.079793   -0.111782  \n",
       "\n",
       "[67804 rows x 61 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read CSV file for Training the model using Pandas\n",
    "df_train = pd.read_csv(\"totol_1output_copy.csv\", header=0)\n",
    "\n",
    "# First we must sort the values of the dataset according to the Alphabets\n",
    "df_train = df_train.sort_values(by=[\"class_type\"])\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab521d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_type</th>\n",
       "      <th>thumb_CmcX</th>\n",
       "      <th>thumb_CmcY</th>\n",
       "      <th>thumb_CmcZ</th>\n",
       "      <th>thumb_McpX</th>\n",
       "      <th>thumb_McpY</th>\n",
       "      <th>thumb_McpZ</th>\n",
       "      <th>thumb_IpX</th>\n",
       "      <th>thumb_IpY</th>\n",
       "      <th>thumb_IpZ</th>\n",
       "      <th>...</th>\n",
       "      <th>pinky_McpZ</th>\n",
       "      <th>pinky_PipX</th>\n",
       "      <th>pinky_PipY</th>\n",
       "      <th>pinky_PipZ</th>\n",
       "      <th>pinky_DipX</th>\n",
       "      <th>pinky_DipY</th>\n",
       "      <th>pinky_DipZ</th>\n",
       "      <th>pinky_TipX</th>\n",
       "      <th>pinky_TipY</th>\n",
       "      <th>pinky_TipZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.078050</td>\n",
       "      <td>0.052410</td>\n",
       "      <td>-0.097754</td>\n",
       "      <td>0.175706</td>\n",
       "      <td>0.077343</td>\n",
       "      <td>-0.128307</td>\n",
       "      <td>0.275970</td>\n",
       "      <td>0.113071</td>\n",
       "      <td>-0.136625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054411</td>\n",
       "      <td>0.357743</td>\n",
       "      <td>0.057897</td>\n",
       "      <td>0.018375</td>\n",
       "      <td>0.358115</td>\n",
       "      <td>0.126840</td>\n",
       "      <td>-0.009358</td>\n",
       "      <td>0.339377</td>\n",
       "      <td>0.179944</td>\n",
       "      <td>-0.019861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.012620</td>\n",
       "      <td>-0.044744</td>\n",
       "      <td>-0.123135</td>\n",
       "      <td>0.018767</td>\n",
       "      <td>-0.079958</td>\n",
       "      <td>-0.195871</td>\n",
       "      <td>0.078375</td>\n",
       "      <td>-0.064984</td>\n",
       "      <td>-0.246966</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099393</td>\n",
       "      <td>0.244468</td>\n",
       "      <td>0.119232</td>\n",
       "      <td>-0.166323</td>\n",
       "      <td>0.178340</td>\n",
       "      <td>0.133267</td>\n",
       "      <td>-0.168216</td>\n",
       "      <td>0.127710</td>\n",
       "      <td>0.125424</td>\n",
       "      <td>-0.154277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.008097</td>\n",
       "      <td>-0.045152</td>\n",
       "      <td>-0.121893</td>\n",
       "      <td>0.024023</td>\n",
       "      <td>-0.080934</td>\n",
       "      <td>-0.193070</td>\n",
       "      <td>0.084990</td>\n",
       "      <td>-0.066602</td>\n",
       "      <td>-0.242528</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089771</td>\n",
       "      <td>0.246310</td>\n",
       "      <td>0.127228</td>\n",
       "      <td>-0.152808</td>\n",
       "      <td>0.181133</td>\n",
       "      <td>0.137645</td>\n",
       "      <td>-0.155199</td>\n",
       "      <td>0.134478</td>\n",
       "      <td>0.129427</td>\n",
       "      <td>-0.141829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.009345</td>\n",
       "      <td>-0.047620</td>\n",
       "      <td>-0.120329</td>\n",
       "      <td>0.021717</td>\n",
       "      <td>-0.085917</td>\n",
       "      <td>-0.190250</td>\n",
       "      <td>0.081786</td>\n",
       "      <td>-0.071348</td>\n",
       "      <td>-0.238580</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090403</td>\n",
       "      <td>0.238301</td>\n",
       "      <td>0.129838</td>\n",
       "      <td>-0.149954</td>\n",
       "      <td>0.173444</td>\n",
       "      <td>0.136199</td>\n",
       "      <td>-0.149373</td>\n",
       "      <td>0.132625</td>\n",
       "      <td>0.123766</td>\n",
       "      <td>-0.134313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.007643</td>\n",
       "      <td>-0.046334</td>\n",
       "      <td>-0.114762</td>\n",
       "      <td>0.018584</td>\n",
       "      <td>-0.086358</td>\n",
       "      <td>-0.183096</td>\n",
       "      <td>0.076390</td>\n",
       "      <td>-0.072655</td>\n",
       "      <td>-0.231085</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084937</td>\n",
       "      <td>0.243161</td>\n",
       "      <td>0.126474</td>\n",
       "      <td>-0.139383</td>\n",
       "      <td>0.179160</td>\n",
       "      <td>0.133866</td>\n",
       "      <td>-0.137239</td>\n",
       "      <td>0.135621</td>\n",
       "      <td>0.121028</td>\n",
       "      <td>-0.121733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>4</td>\n",
       "      <td>0.052386</td>\n",
       "      <td>-0.033384</td>\n",
       "      <td>-0.098482</td>\n",
       "      <td>0.138610</td>\n",
       "      <td>-0.056004</td>\n",
       "      <td>-0.137836</td>\n",
       "      <td>0.236382</td>\n",
       "      <td>-0.034437</td>\n",
       "      <td>-0.167124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010491</td>\n",
       "      <td>0.280510</td>\n",
       "      <td>0.069187</td>\n",
       "      <td>-0.040047</td>\n",
       "      <td>0.219858</td>\n",
       "      <td>0.082490</td>\n",
       "      <td>-0.040654</td>\n",
       "      <td>0.181638</td>\n",
       "      <td>0.064963</td>\n",
       "      <td>-0.023303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>4</td>\n",
       "      <td>0.048063</td>\n",
       "      <td>-0.032764</td>\n",
       "      <td>-0.101829</td>\n",
       "      <td>0.137323</td>\n",
       "      <td>-0.053630</td>\n",
       "      <td>-0.141715</td>\n",
       "      <td>0.239965</td>\n",
       "      <td>-0.031687</td>\n",
       "      <td>-0.169697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017140</td>\n",
       "      <td>0.305112</td>\n",
       "      <td>0.069570</td>\n",
       "      <td>-0.035449</td>\n",
       "      <td>0.245721</td>\n",
       "      <td>0.090840</td>\n",
       "      <td>-0.039726</td>\n",
       "      <td>0.203419</td>\n",
       "      <td>0.077289</td>\n",
       "      <td>-0.025330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>4</td>\n",
       "      <td>0.037981</td>\n",
       "      <td>-0.035757</td>\n",
       "      <td>-0.097611</td>\n",
       "      <td>0.122475</td>\n",
       "      <td>-0.065621</td>\n",
       "      <td>-0.141231</td>\n",
       "      <td>0.224929</td>\n",
       "      <td>-0.046344</td>\n",
       "      <td>-0.173946</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014423</td>\n",
       "      <td>0.309466</td>\n",
       "      <td>0.082511</td>\n",
       "      <td>-0.071618</td>\n",
       "      <td>0.237189</td>\n",
       "      <td>0.098081</td>\n",
       "      <td>-0.065985</td>\n",
       "      <td>0.197453</td>\n",
       "      <td>0.075824</td>\n",
       "      <td>-0.043239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>4</td>\n",
       "      <td>0.053431</td>\n",
       "      <td>-0.017564</td>\n",
       "      <td>-0.097405</td>\n",
       "      <td>0.140951</td>\n",
       "      <td>-0.023345</td>\n",
       "      <td>-0.126577</td>\n",
       "      <td>0.241364</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>-0.140527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058359</td>\n",
       "      <td>0.293261</td>\n",
       "      <td>0.026037</td>\n",
       "      <td>0.026640</td>\n",
       "      <td>0.243700</td>\n",
       "      <td>0.051435</td>\n",
       "      <td>0.023560</td>\n",
       "      <td>0.205439</td>\n",
       "      <td>0.047243</td>\n",
       "      <td>0.034067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.106140</td>\n",
       "      <td>-0.080405</td>\n",
       "      <td>-0.049811</td>\n",
       "      <td>-0.217258</td>\n",
       "      <td>-0.131111</td>\n",
       "      <td>-0.036842</td>\n",
       "      <td>-0.329615</td>\n",
       "      <td>-0.137304</td>\n",
       "      <td>-0.022465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147515</td>\n",
       "      <td>-0.239412</td>\n",
       "      <td>0.085153</td>\n",
       "      <td>0.101772</td>\n",
       "      <td>-0.193454</td>\n",
       "      <td>0.086972</td>\n",
       "      <td>0.074749</td>\n",
       "      <td>-0.142062</td>\n",
       "      <td>0.071546</td>\n",
       "      <td>0.073242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2988 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class_type  thumb_CmcX  thumb_CmcY  thumb_CmcZ  thumb_McpX  thumb_McpY  \\\n",
       "0              2    0.078050    0.052410   -0.097754    0.175706    0.077343   \n",
       "203            2   -0.012620   -0.044744   -0.123135    0.018767   -0.079958   \n",
       "202            2   -0.008097   -0.045152   -0.121893    0.024023   -0.080934   \n",
       "201            2   -0.009345   -0.047620   -0.120329    0.021717   -0.085917   \n",
       "200            2   -0.007643   -0.046334   -0.114762    0.018584   -0.086358   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1990           4    0.052386   -0.033384   -0.098482    0.138610   -0.056004   \n",
       "1989           4    0.048063   -0.032764   -0.101829    0.137323   -0.053630   \n",
       "1988           4    0.037981   -0.035757   -0.097611    0.122475   -0.065621   \n",
       "1997           4    0.053431   -0.017564   -0.097405    0.140951   -0.023345   \n",
       "2987           4   -0.106140   -0.080405   -0.049811   -0.217258   -0.131111   \n",
       "\n",
       "      thumb_McpZ  thumb_IpX  thumb_IpY  thumb_IpZ  ...  pinky_McpZ  \\\n",
       "0      -0.128307   0.275970   0.113071  -0.136625  ...    0.054411   \n",
       "203    -0.195871   0.078375  -0.064984  -0.246966  ...   -0.099393   \n",
       "202    -0.193070   0.084990  -0.066602  -0.242528  ...   -0.089771   \n",
       "201    -0.190250   0.081786  -0.071348  -0.238580  ...   -0.090403   \n",
       "200    -0.183096   0.076390  -0.072655  -0.231085  ...   -0.084937   \n",
       "...          ...        ...        ...        ...  ...         ...   \n",
       "1990   -0.137836   0.236382  -0.034437  -0.167124  ...    0.010491   \n",
       "1989   -0.141715   0.239965  -0.031687  -0.169697  ...    0.017140   \n",
       "1988   -0.141231   0.224929  -0.046344  -0.173946  ...   -0.014423   \n",
       "1997   -0.126577   0.241364   0.000656  -0.140527  ...    0.058359   \n",
       "2987   -0.036842  -0.329615  -0.137304  -0.022465  ...    0.147515   \n",
       "\n",
       "      pinky_PipX  pinky_PipY  pinky_PipZ  pinky_DipX  pinky_DipY  pinky_DipZ  \\\n",
       "0       0.357743    0.057897    0.018375    0.358115    0.126840   -0.009358   \n",
       "203     0.244468    0.119232   -0.166323    0.178340    0.133267   -0.168216   \n",
       "202     0.246310    0.127228   -0.152808    0.181133    0.137645   -0.155199   \n",
       "201     0.238301    0.129838   -0.149954    0.173444    0.136199   -0.149373   \n",
       "200     0.243161    0.126474   -0.139383    0.179160    0.133866   -0.137239   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1990    0.280510    0.069187   -0.040047    0.219858    0.082490   -0.040654   \n",
       "1989    0.305112    0.069570   -0.035449    0.245721    0.090840   -0.039726   \n",
       "1988    0.309466    0.082511   -0.071618    0.237189    0.098081   -0.065985   \n",
       "1997    0.293261    0.026037    0.026640    0.243700    0.051435    0.023560   \n",
       "2987   -0.239412    0.085153    0.101772   -0.193454    0.086972    0.074749   \n",
       "\n",
       "      pinky_TipX  pinky_TipY  pinky_TipZ  \n",
       "0       0.339377    0.179944   -0.019861  \n",
       "203     0.127710    0.125424   -0.154277  \n",
       "202     0.134478    0.129427   -0.141829  \n",
       "201     0.132625    0.123766   -0.134313  \n",
       "200     0.135621    0.121028   -0.121733  \n",
       "...          ...         ...         ...  \n",
       "1990    0.181638    0.064963   -0.023303  \n",
       "1989    0.203419    0.077289   -0.025330  \n",
       "1988    0.197453    0.075824   -0.043239  \n",
       "1997    0.205439    0.047243    0.034067  \n",
       "2987   -0.142062    0.071546    0.073242  \n",
       "\n",
       "[2988 rows x 61 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read CSV file for Validation or Testing the Model using Pandas\n",
    "df_test = pd.read_csv(\"output0_1_copy.csv\", header=0)\n",
    "\n",
    "# First we must sort the values of the dataset according to the Alphabets\n",
    "df_test = df_test.sort_values(by=[\"class_type\"])\n",
    "\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12a5c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put Categorical using Pandas\n",
    "df_train[\"class_type\"] = pd.Categorical(df_train[\"class_type\"])\n",
    "df_train[\"class_type\"] = df_train.class_type.cat.codes\n",
    "\n",
    "df_test[\"class_type\"] = pd.Categorical(df_test[\"class_type\"])\n",
    "df_test[\"class_type\"] = df_test.class_type.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abe3d08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy Label and Feature for training\n",
    "y_train = df_train.pop(\"class_type\")\n",
    "x_train = df_train.copy()\n",
    "\n",
    "y_test = df_test.pop(\"class_type\")\n",
    "x_test = df_test.copy()\n",
    "\n",
    "# Copied Features turn to Array by using NumPy\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f287097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67804, 60)\n",
      "(2988, 60)\n",
      "(67804, 60, 1)\n",
      "(2988, 60, 1)\n"
     ]
    }
   ],
   "source": [
    "# Check Array Shape before transformation\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "# Since the array shape is 1x1, we must turn it into 1x10x1 so we can feed it into the model\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "# Check Array Shape after transformation\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ed85f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.012]\n",
      " [-0.055]\n",
      " [-0.065]\n",
      " [ 0.046]\n",
      " [-0.082]\n",
      " [-0.106]\n",
      " [ 0.075]\n",
      " [-0.069]\n",
      " [-0.143]\n",
      " [ 0.106]\n",
      " [-0.031]\n",
      " [-0.176]\n",
      " [ 0.101]\n",
      " [-0.03 ]\n",
      " [-0.084]\n",
      " [ 0.098]\n",
      " [ 0.002]\n",
      " [-0.139]\n",
      " [ 0.039]\n",
      " [ 0.028]\n",
      " [-0.174]\n",
      " [-0.021]\n",
      " [ 0.038]\n",
      " [-0.189]\n",
      " [ 0.083]\n",
      " [ 0.027]\n",
      " [-0.073]\n",
      " [ 0.072]\n",
      " [ 0.056]\n",
      " [-0.136]\n",
      " [-0.003]\n",
      " [ 0.074]\n",
      " [-0.165]\n",
      " [-0.07 ]\n",
      " [ 0.072]\n",
      " [-0.175]\n",
      " [ 0.065]\n",
      " [ 0.076]\n",
      " [-0.067]\n",
      " [ 0.051]\n",
      " [ 0.1  ]\n",
      " [-0.135]\n",
      " [-0.021]\n",
      " [ 0.111]\n",
      " [-0.146]\n",
      " [-0.082]\n",
      " [ 0.102]\n",
      " [-0.138]\n",
      " [ 0.046]\n",
      " [ 0.111]\n",
      " [-0.064]\n",
      " [ 0.048]\n",
      " [ 0.14 ]\n",
      " [-0.112]\n",
      " [ 0.002]\n",
      " [ 0.15 ]\n",
      " [-0.113]\n",
      " [-0.044]\n",
      " [ 0.142]\n",
      " [-0.104]]\n",
      "[[-0.012]\n",
      " [-0.039]\n",
      " [-0.124]\n",
      " [ 0.028]\n",
      " [-0.076]\n",
      " [-0.196]\n",
      " [ 0.092]\n",
      " [-0.065]\n",
      " [-0.248]\n",
      " [ 0.163]\n",
      " [-0.073]\n",
      " [-0.292]\n",
      " [ 0.205]\n",
      " [-0.165]\n",
      " [-0.149]\n",
      " [ 0.258]\n",
      " [-0.12 ]\n",
      " [-0.255]\n",
      " [ 0.244]\n",
      " [-0.05 ]\n",
      " [-0.328]\n",
      " [ 0.215]\n",
      " [ 0.007]\n",
      " [-0.365]\n",
      " [ 0.245]\n",
      " [-0.094]\n",
      " [-0.119]\n",
      " [ 0.312]\n",
      " [ 0.04 ]\n",
      " [ 0.693]\n",
      " [ 0.249]\n",
      " [ 0.038]\n",
      " [-0.282]\n",
      " [ 0.187]\n",
      " [ 0.067]\n",
      " [-0.295]\n",
      " [ 0.255]\n",
      " [-0.019]\n",
      " [-0.101]\n",
      " [ 0.287]\n",
      " [ 0.065]\n",
      " [-0.2  ]\n",
      " [ 0.202]\n",
      " [ 0.099]\n",
      " [-0.208]\n",
      " [ 0.138]\n",
      " [ 0.098]\n",
      " [-0.191]\n",
      " [ 0.239]\n",
      " [ 0.047]\n",
      " [-0.092]\n",
      " [ 0.256]\n",
      " [ 0.117]\n",
      " [-0.16 ]\n",
      " [ 0.186]\n",
      " [ 0.128]\n",
      " [-0.161]\n",
      " [ 0.136]\n",
      " [ 0.113]\n",
      " [-0.144]]\n"
     ]
    }
   ],
   "source": [
    "# Check sample train and test features\n",
    "print(x_train[0])\n",
    "print(x_test[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bd648d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of classes according standard Indonesian Language Alphabets\n",
    "num_classes = 5\n",
    "\n",
    "# Using the Keras.Utils to put the label categorically \n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9dc28c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 60, 32)            192       \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 60, 32)            5152      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 30, 32)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 30, 64)            10304     \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 30, 64)            20544     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 15, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 15, 128)           41088     \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 15, 128)           82048     \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 7, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 7, 256)            164096    \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 7, 256)            327936    \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 3, 256)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 3, 256)            0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 768)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               393728    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 2565      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,047,653\n",
      "Trainable params: 1,047,653\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# One Dimensional Convolutional Neural Network model, Train will be feed to 1 Dimension Convolutional Neural Network\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\", input_shape=x_train.shape[1:3]),\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Conv1D(filters=64, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n",
    "    tf.keras.layers.Conv1D(filters=64, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Conv1D(filters=128, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n",
    "    tf.keras.layers.Conv1D(filters=128, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Conv1D(filters=256, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n",
    "    tf.keras.layers.Conv1D(filters=256, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'), \n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')])\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4aa5694e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "3391/3391 [==============================] - 260s 73ms/step - loss: 0.4980 - accuracy: 0.8029 - val_loss: 4.6728 - val_accuracy: 0.0499\n",
      "Epoch 2/40\n",
      "3391/3391 [==============================] - 257s 76ms/step - loss: 0.2132 - accuracy: 0.9265 - val_loss: 4.6686 - val_accuracy: 0.0636\n",
      "Epoch 3/40\n",
      "3391/3391 [==============================] - 257s 76ms/step - loss: 0.1633 - accuracy: 0.9439 - val_loss: 5.8625 - val_accuracy: 0.0281\n",
      "Epoch 4/40\n",
      "3391/3391 [==============================] - 257s 76ms/step - loss: 0.1380 - accuracy: 0.9538 - val_loss: 6.2342 - val_accuracy: 0.0184\n",
      "Epoch 5/40\n",
      "3391/3391 [==============================] - 257s 76ms/step - loss: 0.1205 - accuracy: 0.9603 - val_loss: 7.4632 - val_accuracy: 0.0408\n",
      "Epoch 6/40\n",
      "3391/3391 [==============================] - 244s 72ms/step - loss: 0.1077 - accuracy: 0.9639 - val_loss: 6.0267 - val_accuracy: 0.0254\n",
      "Epoch 7/40\n",
      "3391/3391 [==============================] - 259s 76ms/step - loss: 0.1020 - accuracy: 0.9672 - val_loss: 7.4299 - val_accuracy: 0.0469\n",
      "Epoch 8/40\n",
      "3391/3391 [==============================] - 258s 76ms/step - loss: 0.0985 - accuracy: 0.9687 - val_loss: 7.2955 - val_accuracy: 0.0100\n",
      "Epoch 9/40\n",
      "3391/3391 [==============================] - 256s 75ms/step - loss: 0.0842 - accuracy: 0.9731 - val_loss: 11.7527 - val_accuracy: 0.0154\n",
      "Epoch 10/40\n",
      "3391/3391 [==============================] - 261s 77ms/step - loss: 0.0878 - accuracy: 0.9717 - val_loss: 11.6090 - val_accuracy: 0.0515\n",
      "Epoch 11/40\n",
      "3391/3391 [==============================] - 258s 76ms/step - loss: 0.0845 - accuracy: 0.9733 - val_loss: 11.9797 - val_accuracy: 0.0549\n",
      "Epoch 12/40\n",
      "3391/3391 [==============================] - 256s 76ms/step - loss: 0.0796 - accuracy: 0.9744 - val_loss: 8.5248 - val_accuracy: 0.0679\n",
      "Epoch 13/40\n",
      "3391/3391 [==============================] - 256s 76ms/step - loss: 0.0817 - accuracy: 0.9739 - val_loss: 16.8291 - val_accuracy: 0.0218\n",
      "Epoch 14/40\n",
      "3391/3391 [==============================] - 256s 76ms/step - loss: 0.0907 - accuracy: 0.9718 - val_loss: 14.3429 - val_accuracy: 0.0726\n",
      "Epoch 15/40\n",
      "3391/3391 [==============================] - 256s 76ms/step - loss: 0.0752 - accuracy: 0.9763 - val_loss: 11.3336 - val_accuracy: 0.0566\n",
      "Epoch 16/40\n",
      "3391/3391 [==============================] - 256s 76ms/step - loss: 0.0780 - accuracy: 0.9771 - val_loss: 24.4541 - val_accuracy: 0.0298\n",
      "Epoch 17/40\n",
      "3391/3391 [==============================] - 256s 76ms/step - loss: 0.0694 - accuracy: 0.9787 - val_loss: 21.5404 - val_accuracy: 0.0341\n",
      "Epoch 18/40\n",
      "3391/3391 [==============================] - 256s 76ms/step - loss: 0.0791 - accuracy: 0.9763 - val_loss: 10.4272 - val_accuracy: 0.0813\n",
      "Epoch 19/40\n",
      "3391/3391 [==============================] - 256s 76ms/step - loss: 0.0694 - accuracy: 0.9783 - val_loss: 15.6029 - val_accuracy: 0.0760\n",
      "Epoch 20/40\n",
      "3391/3391 [==============================] - 258s 76ms/step - loss: 0.0797 - accuracy: 0.9764 - val_loss: 18.2628 - val_accuracy: 0.0077\n",
      "Epoch 21/40\n",
      "3391/3391 [==============================] - 259s 76ms/step - loss: 0.0644 - accuracy: 0.9789 - val_loss: 62.7687 - val_accuracy: 0.0013\n",
      "Epoch 22/40\n",
      "3391/3391 [==============================] - 258s 76ms/step - loss: 0.0751 - accuracy: 0.9780 - val_loss: 11.8484 - val_accuracy: 0.0810\n",
      "Epoch 23/40\n",
      "3391/3391 [==============================] - 257s 76ms/step - loss: 0.0694 - accuracy: 0.9785 - val_loss: 24.8333 - val_accuracy: 0.1841\n",
      "Epoch 24/40\n",
      "3391/3391 [==============================] - 257s 76ms/step - loss: 0.0807 - accuracy: 0.9769 - val_loss: 10.1259 - val_accuracy: 0.0830\n",
      "Epoch 25/40\n",
      "3391/3391 [==============================] - 257s 76ms/step - loss: 0.1794 - accuracy: 0.9656 - val_loss: 21.8607 - val_accuracy: 0.0278\n",
      "Epoch 26/40\n",
      "3391/3391 [==============================] - 257s 76ms/step - loss: 0.0605 - accuracy: 0.9821 - val_loss: 31.0157 - val_accuracy: 0.0348\n",
      "Epoch 27/40\n",
      "3391/3391 [==============================] - 257s 76ms/step - loss: 0.0729 - accuracy: 0.9799 - val_loss: 15.3405 - val_accuracy: 0.0385\n",
      "Epoch 28/40\n",
      "3391/3391 [==============================] - 258s 76ms/step - loss: 0.0928 - accuracy: 0.9714 - val_loss: 15.8528 - val_accuracy: 0.0361\n",
      "Epoch 29/40\n",
      "3391/3391 [==============================] - 257s 76ms/step - loss: 0.0660 - accuracy: 0.9802 - val_loss: 6.5314 - val_accuracy: 0.0177\n",
      "Epoch 30/40\n",
      "3391/3391 [==============================] - 258s 76ms/step - loss: 0.0628 - accuracy: 0.9805 - val_loss: 8.0081 - val_accuracy: 0.0278\n",
      "Epoch 31/40\n",
      "3391/3391 [==============================] - 258s 76ms/step - loss: 0.0704 - accuracy: 0.9798 - val_loss: 16.0129 - val_accuracy: 0.0131\n",
      "Epoch 32/40\n",
      "3391/3391 [==============================] - 257s 76ms/step - loss: 0.0641 - accuracy: 0.9808 - val_loss: 9.8106 - val_accuracy: 0.0790\n",
      "Epoch 33/40\n",
      "3391/3391 [==============================] - 258s 76ms/step - loss: 0.0629 - accuracy: 0.9813 - val_loss: 5.4665 - val_accuracy: 0.0730\n",
      "Epoch 34/40\n",
      "3391/3391 [==============================] - 258s 76ms/step - loss: 0.1090 - accuracy: 0.9715 - val_loss: 6.6858 - val_accuracy: 0.1305\n",
      "Epoch 35/40\n",
      "3391/3391 [==============================] - 258s 76ms/step - loss: 0.0619 - accuracy: 0.9815 - val_loss: 9.2721 - val_accuracy: 0.1891\n",
      "Epoch 36/40\n",
      "3391/3391 [==============================] - 258s 76ms/step - loss: 0.0687 - accuracy: 0.9799 - val_loss: 12.3279 - val_accuracy: 0.0141\n",
      "Epoch 37/40\n",
      "3391/3391 [==============================] - 258s 76ms/step - loss: 0.0703 - accuracy: 0.9794 - val_loss: 8.5323 - val_accuracy: 0.1519\n",
      "Epoch 38/40\n",
      "3391/3391 [==============================] - 258s 76ms/step - loss: 0.0800 - accuracy: 0.9788 - val_loss: 8.7013 - val_accuracy: 0.0924\n",
      "Epoch 39/40\n",
      "3391/3391 [==============================] - 257s 76ms/step - loss: 0.0641 - accuracy: 0.9813 - val_loss: 15.9122 - val_accuracy: 0.0415\n",
      "Epoch 40/40\n",
      "3391/3391 [==============================] - 257s 76ms/step - loss: 0.0704 - accuracy: 0.9806 - val_loss: 10.2666 - val_accuracy: 3.3467e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e321f1e670>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the Model\n",
    "model.fit(x_train, y_train, epochs=40, batch_size=20, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0860a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved into CNN_origin.h5\n"
     ]
    }
   ],
   "source": [
    "#Saving the model into H5 system file\n",
    "save_model = \"CNN_origin.h5\"\n",
    "model.save(save_model)\n",
    "print(\"Model Saved into\", save_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c6d92d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
